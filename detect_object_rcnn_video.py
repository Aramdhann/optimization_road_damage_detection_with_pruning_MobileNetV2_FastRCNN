# USAGE
# import the necessary packages
import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

import tensorflow_model_optimization as tfmot
from pyimagesearch.nms import non_max_suppression
from pyimagesearch import config
from keras.applications.mobilenet_v2 import preprocess_input
from keras.utils import img_to_array
from keras.models import load_model
import numpy as np
import imutils
import pickle
import cv2
from pyimagesearch import config
import pandas as pd

# =================
# PENS 2023
# =================

#Fungsi text
def draw_text(img, text,
          font=cv2.FONT_HERSHEY_PLAIN,
          pos=(0, 0),
          font_scale=1,
          font_thickness=1,
          text_color=(0, 0, 0),
          text_color_bg=(0, 255, 0)
          ):

    x, y = pos
    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)
    text_w, text_h = text_size
    cv2.rectangle(img, pos, (x + 5 + text_w + 6, y - text_h - 8), text_color_bg, -1)
    cv2.putText(img, text, (x + 5, y - text_h + 6 + font_scale - 1), font, font_scale, text_color, font_thickness)

    return text_size

# load the our fine-tuned model and label encoding from disk
print("[INFO] loading model and label encoding...")

model = load_model(config.MODEL_PATH)  # , custom_objects= custom_objects)

lb = pickle.loads(open(config.ENCODER_PATH, "rb").read())

print(model.summary())
print(lb)

# cap = cv2.VideoCapture(0)
cap = cv2.VideoCapture("vid2.avi") #0 untuk webcam "vid2.avi" untuk file video
if not cap.isOpened():
    print("Error opening camera")
    exit()

if config.VIDEORESULT:
    frame_width = int(cap.get(3))
    frame_height = int(cap.get(4))
    size = (frame_width, frame_height)
    result = cv2.VideoWriter('output.avi',
                             cv2.VideoWriter_fourcc(*'MJPG'),
                             10, size)

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    # If frame is read correctly, ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break


    # Set the frame size
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # load the input image from disk
    #image = cv2.imread(frame)
    # image = imutils.resize(image, width=500)
    #image = cv2.resize(frame, (224, 224))
    image = frame
    image = imutils.resize(image, width=500)
    show = frame
    # image = np.expand_dims(image, axis=0)
    # image = image / 255.0

    # run selective search on the image to generate bounding box proposal
    # regions
    print("[INFO] running selective search...")
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()

    # initialize the list of region proposals that we'll be classifying
    # along with their associated bounding boxes
    proposals = []
    boxes = []

    # loop over the region proposal bounding box coordinates generated by
    # running selective search
    for (x, y, w, h) in rects[:config.MAX_PROPOSALS_INFER]:
        # extract the region from the input image, convert it from BGR to
        # RGB channel ordering, and then resize it to the required input
        # dimensions of our trained CNN
        roi = image[y:y + h, x:x + w]
        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
        roi = cv2.resize(roi, config.INPUT_DIMS,
                         interpolation=cv2.INTER_CUBIC)

        # further preprocess by the ROI
        roi = img_to_array(roi)
        roi = preprocess_input(roi)

        # update our proposals and bounding boxes lists
        proposals.append(roi)
        boxes.append((x, y, x + w, y + h))

    # convert the proposals and bounding boxes into NumPy arrays
    proposals = np.array(proposals, dtype="float32")
    boxes = np.array(boxes, dtype="int32")
    print("[INFO] proposal shape: {}".format(proposals.shape))

    # classify each of the proposal ROIs using fine-tuned model
    print("[INFO] classifying...")
    proba = model.predict(proposals)

    # find the index of all predictions that are positive for the
    # multiclass
    print("[INFO] applying NMS...")
    labels = lb.classes_[np.argmax(proba, axis=1)]

    # Create dataframe
    data = []
    for idx in range(len(labels)):
        data.append([idx, boxes[idx], proba[idx], np.max(proba[idx]), labels[idx]])
    data_df = pd.DataFrame(data, columns=["idx", "box", "scores", "score", "label"])

    # Create dictionary to save labelled box and labelled score
    unique_label = data_df["label"].drop_duplicates().to_list()
    data_dict = {}
    for label in unique_label:
        data_label = data_df[data_df["label"] == label][["box", "score"]]
        data_label = data_label[data_label["score"] >= config.MIN_PROBA]
        data_dict[label] = {
            "box": data_label["box"].to_list(),
            "score": data_label["score"].to_list(),
        }

    # join the overlapping bounding box + draw
    data_dict_suppression = {}
    for label in unique_label:
        idx_suppression = non_max_suppression(np.array(data_dict[label]["box"]), np.array(data_dict[label]["score"]))
        for idx in idx_suppression:
            if label != "no_label":
                if data_dict[label]["box"] and data_dict[label]["score"]:
                    (startX, startY, endX, endY) = data_dict[label]["box"][idx]
                    cv2.rectangle(show, (startX, startY), (endX, endY),
                                  (0, 255, 0), 2)
                    y = startY - 10 if startY - 10 > 10 else startY + 10
                    text = "{} {:.2f}%".format(label, data_dict[label]["score"][idx] * 100)
                    # cv2.putText(show, text, (startX, y),
                    #             cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)
                    draw_text(show, text=text, pos=(startX,startY))

    # Display the resulting frame
    cv2.imshow('frame', show)
    if config.VIDEORESULT:
        result.write(show)

    # Press 'q' to exit
    if cv2.waitKey(1) == ord('q'):
        break

# When everything done, release the capture
cap.release()
if config.VIDEORESULT:
    result.release()
cv2.destroyAllWindows()
