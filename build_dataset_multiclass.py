from pyimagesearch.iou import compute_iou
from pyimagesearch import config
from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os

from keras.utils import img_to_array
from keras.utils import load_img
from keras.utils import to_categorical
from keras.applications.mobilenet_v2 import preprocess_input

#===== 
# PENS 2023
#=====

imagePaths = []
totalPositive = 0
totalNegative = 0

for x in sorted(list(paths.list_images(config.DATASETXML))):
    imagePaths.append(x)

gtBoxess = []
# loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
	# show a progress report
	print("[INFO] processing image {}/{}...".format(i + 1,
		len(imagePaths)))
	
	filename = imagePath.split("\\")[-1].split(".")[0]
	imagePath_no_ext = imagePath.split(".")[0]
	annotPath = "{}.xml".format(imagePath_no_ext)
	
	# load the annotation file, build the soup, and initialize our
	# list of ground-truth bounding boxes
	contents = open(annotPath).read()
	soup = BeautifulSoup(contents, "html.parser")
	gtBoxes = []

	w = int(soup.find("width").string)
	h = int(soup.find("height").string)	

	# loop over all 'object' elements
	for o in soup.find_all("object"):
		# extract the label and bounding box coordinates
		label = o.find("name").string
		xMin = int(o.find("xmin").string)
		yMin = int(o.find("ymin").string)
		xMax = int(o.find("xmax").string)
		yMax = int(o.find("ymax").string)

		# truncate any bounding box coordinates that may fall
		# outside the boundaries of the image
		xMin = max(0, xMin)
		yMin = max(0, yMin)
		xMax = min(w, xMax)
		yMax = min(h, yMax)

		# update our list of ground-truth bounding boxes
		gtBoxes.append((filename,label, (xMin, yMin, xMax, yMax)))	
		gtBoxess.append((filename,label, (xMin, yMin, xMax, yMax)))	

	
	#Process Predictions to grab image outside the label
	image = cv2.imread(imagePath)
	ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
	ss.setBaseImage(image)
	ss.switchToSelectiveSearchFast()
	rects = ss.process()

	proposedRects= []
	# loop over the rectangles generated by selective search
	for (x, y, w, h) in rects:
		# convert our bounding boxes from (x, y, w, h) to (startX,
		# startY, startX, endY)
		proposedRects.append((x, y, x + w, y + h))
	
	# initialize counters used to count the number of positive and
	# negative ROIs saved thus far
	positiveROIs = 0
	negativeROIs = 0

	for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
		# unpack the proposed rectangle bounding box
		(propStartX, propStartY, propEndX, propEndY) = proposedRect

		# loop over the ground-truth bounding boxes
		for filename, label, gtBox in gtBoxes:
			# compute the intersection over union between the two
			# boxes and unpack the ground-truth bounding box
			iou = compute_iou(gtBox, proposedRect)
			(gtStartX, gtStartY, gtEndX, gtEndY) = gtBox

			# initialize the ROI and output path
			roi = None
			outputPath = None

			# check to see if the IOU is greater than 70% *and* that
			# we have not hit our positive count limit
			if iou > 0.75 and positiveROIs <= config.MAX_POSITIVE:
				# extract the ROI and then derive the output path to
				# the positive instance
				roi = image[propStartY:propEndY, propStartX:propEndX]
				filepath = "{}_{}_{}.png".format(label,filename,totalPositive)
				
				dirPath = f"dataset\\{label}"
				if not os.path.exists(dirPath):
					os.makedirs(dirPath)

				outputPath = os.path.sep.join([dirPath,
					filepath])

				# increment the positive counters
				positiveROIs += 1
				totalPositive += 1
			

			#Check Overlap
			# determine if the proposed bounding box falls *within*
			# the ground-truth bounding box
			fullOverlap = propStartX >= gtStartX
			fullOverlap = fullOverlap and propStartY >= gtStartY
			fullOverlap = fullOverlap and propEndX <= gtEndX
			fullOverlap = fullOverlap and propEndY <= gtEndY

			# check to see if there is not full overlap *and* the IoU
			# is less than 5% *and* we have not hit our negative
			# count limit
			if not fullOverlap and iou < 0.05 and \
				negativeROIs <= config.MAX_NEGATIVE:
				# extract the ROI and then derive the output path to
				# the negative instance
				roi = image[propStartY:propEndY, propStartX:propEndX]
				filepath = "{}_{}.png".format(filename,totalNegative)
				
				dirPath = f"dataset\\no_label"
				if not os.path.exists(dirPath):
					os.makedirs(dirPath)

				outputPath = os.path.sep.join([dirPath,
					filepath])
				
				# increment the negative counters
				negativeROIs += 1
				totalNegative += 1
			
			# check to see if both the ROI and output path are valid
			if roi is not None and outputPath is not None:
				# resize the ROI to the input dimensions of the CNN
				# that we'll be fine-tuning, then write the ROI to
				# disk
				roi = cv2.resize(roi, config.INPUT_DIMS,
					interpolation=cv2.INTER_CUBIC)
				cv2.imwrite(outputPath, roi)
	
	